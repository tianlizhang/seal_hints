{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import itertools\n",
    "import sys\n",
    "import torch\n",
    "from utils import myout\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_top_k(a, top_k=50):\n",
    "    ele_idx = heapq.nlargest(top_k, zip(a, itertools.count()))\n",
    "    return np.array([idx for ele, idx in ele_idx], dtype=np.intc)\n",
    "\n",
    "def precision(rank, ground_truth):\n",
    "    hits = [1 if item in ground_truth else 0 for item in rank]\n",
    "    result = np.cumsum(hits, dtype=np.float)/np.arange(1, len(rank)+1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def recall(rank, ground_truth):\n",
    "    hits = [1 if item in ground_truth else 0 for item in rank]\n",
    "    result = np.cumsum(hits, dtype=np.float) / len(ground_truth)\n",
    "    return result\n",
    "\n",
    "\n",
    "def map(rank, ground_truth):\n",
    "    pre = precision(rank, ground_truth)\n",
    "    pre = [pre[idx] if item in ground_truth else 0 for idx, item in enumerate(rank)]\n",
    "    sum_pre = np.cumsum(pre, dtype=np.float32)\n",
    "    gt_len = len(ground_truth)\n",
    "    # len_rank = np.array([min(i, gt_len) for i in range(1, len(rank)+1)])\n",
    "    result = sum_pre/gt_len\n",
    "    return result\n",
    "\n",
    "\n",
    "def ndcg(rank, ground_truth):\n",
    "    len_rank = len(rank)\n",
    "    len_gt = len(ground_truth)\n",
    "    idcg_len = min(len_gt, len_rank)\n",
    "\n",
    "    # calculate idcg\n",
    "    idcg = np.cumsum(1.0 / np.log2(np.arange(2, len_rank + 2)))\n",
    "    idcg[idcg_len:] = idcg[idcg_len-1]\n",
    "\n",
    "    # idcg = np.cumsum(1.0/np.log2(np.arange(2, len_rank+2)))\n",
    "    dcg = np.cumsum([1.0/np.log2(idx+2) if item in ground_truth else 0.0 for idx, item in enumerate(rank)])\n",
    "    result = dcg/idcg\n",
    "    return result\n",
    "\n",
    "\n",
    "def mrr(rank, ground_truth):\n",
    "    last_idx = sys.maxsize\n",
    "    for idx, item in enumerate(rank):\n",
    "        if item in ground_truth:\n",
    "            last_idx = idx\n",
    "            break\n",
    "    result = np.zeros(len(rank), dtype=np.float32)\n",
    "    result[last_idx:] = 1.0/(last_idx+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.33333334, 0.33333334, 0.33333334,\n",
       "       0.33333334, 0.33333334], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [5, 5, 4, 0, 1, 2, 3]\n",
    "gt = [0, 1, 2, 3, 4]\n",
    "mrr(pred, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_pos : shape=torch.Size([2]), tensor([0.7000, 0.8801])\n",
      "y_pred_neg : shape=torch.Size([2, 10])\n",
      "tensor([[0.2917, 0.7910, 0.7456, 0.5775, 0.8039, 0.7220, 0.5861, 0.8793, 0.3455,\n",
      "         0.1295],\n",
      "        [0.2793, 0.3745, 0.3292, 0.0028, 0.1132, 0.3431, 0.5361, 0.2225, 0.9813,\n",
      "         0.8049]])\n"
     ]
    }
   ],
   "source": [
    "y_pred_pos = torch.rand(2)\n",
    "y_pred_neg = torch.rand(2, 10)\n",
    "myout(y_pred_pos, y_pred_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred : shape=torch.Size([2, 11])\n",
      "tensor([[0.7000, 0.2917, 0.7910, 0.7456, 0.5775, 0.8039, 0.7220, 0.5861, 0.8793,\n",
      "         0.3455, 0.1295],\n",
      "        [0.8801, 0.2793, 0.3745, 0.3292, 0.0028, 0.1132, 0.3431, 0.5361, 0.2225,\n",
      "         0.9813, 0.8049]])\n",
      "argsort : shape=torch.Size([2, 11])\n",
      "tensor([[ 8,  5,  2,  3,  6,  0,  7,  4,  9,  1, 10],\n",
      "        [ 9,  0, 10,  7,  2,  6,  3,  1,  8,  5,  4]])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.cat([y_pred_pos.view(-1,1), y_pred_neg], dim = 1) # [b, k+1]\n",
    "argsort = torch.argsort(y_pred, dim = 1, descending = True) # [b, k+1]\n",
    "myout(y_pred, argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking_list : shape=torch.Size([2]), tensor([6, 2])\n",
      "hits5_list : shape=torch.Size([2]), tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "ranking_list = torch.nonzero(argsort == 0, as_tuple=False) \n",
    "ranking_list = ranking_list[:, 1] + 1\n",
    "hits5_list = (ranking_list <= 5).to(torch.float)\n",
    "myout(ranking_list, hits5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr : shape=torch.Size([]), 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "mrr_list = 1./ranking_list.to(torch.float)\n",
    "mrr = mrr_list.mean()\n",
    "myout(mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred : shape=torch.Size([2, 11])\n",
      "tensor([[0.7000, 0.2917, 0.7910, 0.7456, 0.5775, 0.8039, 0.7220, 0.5861, 0.8793,\n",
      "         0.3455, 0.1295],\n",
      "        [0.8801, 0.2793, 0.3745, 0.3292, 0.0028, 0.1132, 0.3431, 0.5361, 0.2225,\n",
      "         0.9813, 0.8049]])\n",
      "true_rel : shape=torch.Size([2, 11])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "ndcg = 0.49356847033973983\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.cat([y_pred_pos.view(-1,1), y_pred_neg], dim = 1) # [b, k+1]\n",
    "true_rel = torch.zeros_like(y_pred) # [b, k+1]\n",
    "true_rel[:, 0] = 1\n",
    "ndcg = metrics.ndcg_score(true_rel, y_pred)\n",
    "myout(y_pred, true_rel, ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cor = 0.2990668717675361\n"
     ]
    }
   ],
   "source": [
    "cor, _ = stats.spearmanr(true_rel.view(-1), y_pred.view(-1))\n",
    "myout(cor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3f827d9b2324c578c2246ccacaa141ce13c02e698e0dcc0a6cf117a3692e9a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
